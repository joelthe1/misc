{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3914afd8-5cf9-4ca6-919b-4236bb0d2d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitter\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from shutil import copy2\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a89c0086-e6e9-46a8-aa47-89c0c80e9e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "DATA_DIR = '/nas/home/joel/src/metis/projectmetis/projectmetis/experiments/run_fedmodels/ner/tf_ner/data/conll2003'\n",
    "OUTPUT_DIR = '/lfs1/shared/nlp/conll2003data/conll2003_partitions/federated_non_uniform_random/32-way'\n",
    "\n",
    "# Read Training data\n",
    "train_sentences = pd.read_csv(f'{DATA_DIR}/train.words.txt', sep='|', header=None, names=['sentence'], quoting=3).sentence.to_numpy()\n",
    "train_tags = pd.read_csv(f'{DATA_DIR}/train.tags.txt', sep='|', header=None, names=['tags'], converters={'tags': lambda x: x.split()}).tags.to_numpy()\n",
    "\n",
    "# Read Validation data\n",
    "valid_sentences = pd.read_csv(f'{DATA_DIR}/valid.words.txt', sep='|', header=None, names=['sentence'], quoting=3).sentence.to_numpy()\n",
    "valid_tags = pd.read_csv(f'{DATA_DIR}/valid.tags.txt', sep='|', header=None, names=['tags'], converters={'tags': lambda x: x.split()}).tags.to_numpy()\n",
    "\n",
    "# Concatenate training and validation set\n",
    "train_valid_sentences_concat = np.concatenate((train_sentences, valid_sentences))\n",
    "train_valid_tags_concat = np.concatenate((train_tags, valid_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "054f2c40-20a5-4c79-857f-1e05c7eef9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17291"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_valid_tags_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3e3f23e6-a76a-4080-907b-615b3a8bc2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 32\n",
    "X = 200\n",
    "y = 21.95\n",
    "split_sizes = []\n",
    "for split_number in range(N-1):\n",
    "    split_sizes.append(X+math.ceil(split_number*y))\n",
    "\n",
    "#split_sizes.append(len(train_valid_tags_concat)-sum(split_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4beef171-84b4-4962-a0e7-ecf45034f88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16419"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(split_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bcafb2a0-89f3-4b21-bab1-84d5c490de0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "859130ed-43d1-4ef6-a796-e3f402208de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200,\n",
       " 222,\n",
       " 244,\n",
       " 266,\n",
       " 288,\n",
       " 310,\n",
       " 332,\n",
       " 354,\n",
       " 376,\n",
       " 398,\n",
       " 420,\n",
       " 442,\n",
       " 464,\n",
       " 486,\n",
       " 508,\n",
       " 530,\n",
       " 552,\n",
       " 574,\n",
       " 596,\n",
       " 618,\n",
       " 639,\n",
       " 661,\n",
       " 683,\n",
       " 705,\n",
       " 727,\n",
       " 749,\n",
       " 771,\n",
       " 793,\n",
       " 815,\n",
       " 837,\n",
       " 859]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2e3019bf-564d-4262-be81-22b871a52d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_points = split_sizes[:]\n",
    "for i in range(len(split_points)-1):\n",
    "    split_points[i+1] += split_points[i]\n",
    "\n",
    "rng = np.random.default_rng(12345)\n",
    "indices = np.arange(len(train_valid_tags_concat))\n",
    "rng.shuffle(indices)\n",
    "\n",
    "split_indices = np.split(indices, split_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7ace3572-4b93-4751-8e9a-602df5441a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17291\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for split in split_indices:\n",
    "    total += len(split)\n",
    "assert len(train_valid_tags_concat) == total, \"Something wrong with the splits. Does not add.\"\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "968a8d60-2672-471d-b067-0d8f9dd14ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating split 1\n",
      "Number of train examples = 190\n",
      "Number of dev examples = 10\n",
      "Total = 200\n",
      "-----\n",
      "\n",
      "Creating split 2\n",
      "Number of train examples = 210\n",
      "Number of dev examples = 12\n",
      "Total = 222\n",
      "-----\n",
      "\n",
      "Creating split 3\n",
      "Number of train examples = 231\n",
      "Number of dev examples = 13\n",
      "Total = 244\n",
      "-----\n",
      "\n",
      "Creating split 4\n",
      "Number of train examples = 252\n",
      "Number of dev examples = 14\n",
      "Total = 266\n",
      "-----\n",
      "\n",
      "Creating split 5\n",
      "Number of train examples = 273\n",
      "Number of dev examples = 15\n",
      "Total = 288\n",
      "-----\n",
      "\n",
      "Creating split 6\n",
      "Number of train examples = 294\n",
      "Number of dev examples = 16\n",
      "Total = 310\n",
      "-----\n",
      "\n",
      "Creating split 7\n",
      "Number of train examples = 315\n",
      "Number of dev examples = 17\n",
      "Total = 332\n",
      "-----\n",
      "\n",
      "Creating split 8\n",
      "Number of train examples = 336\n",
      "Number of dev examples = 18\n",
      "Total = 354\n",
      "-----\n",
      "\n",
      "Creating split 9\n",
      "Number of train examples = 357\n",
      "Number of dev examples = 19\n",
      "Total = 376\n",
      "-----\n",
      "\n",
      "Creating split 10\n",
      "Number of train examples = 378\n",
      "Number of dev examples = 20\n",
      "Total = 398\n",
      "-----\n",
      "\n",
      "Creating split 11\n",
      "Number of train examples = 399\n",
      "Number of dev examples = 21\n",
      "Total = 420\n",
      "-----\n",
      "\n",
      "Creating split 12\n",
      "Number of train examples = 419\n",
      "Number of dev examples = 23\n",
      "Total = 442\n",
      "-----\n",
      "\n",
      "Creating split 13\n",
      "Number of train examples = 440\n",
      "Number of dev examples = 24\n",
      "Total = 464\n",
      "-----\n",
      "\n",
      "Creating split 14\n",
      "Number of train examples = 461\n",
      "Number of dev examples = 25\n",
      "Total = 486\n",
      "-----\n",
      "\n",
      "Creating split 15\n",
      "Number of train examples = 482\n",
      "Number of dev examples = 26\n",
      "Total = 508\n",
      "-----\n",
      "\n",
      "Creating split 16\n",
      "Number of train examples = 503\n",
      "Number of dev examples = 27\n",
      "Total = 530\n",
      "-----\n",
      "\n",
      "Creating split 17\n",
      "Number of train examples = 524\n",
      "Number of dev examples = 28\n",
      "Total = 552\n",
      "-----\n",
      "\n",
      "Creating split 18\n",
      "Number of train examples = 545\n",
      "Number of dev examples = 29\n",
      "Total = 574\n",
      "-----\n",
      "\n",
      "Creating split 19\n",
      "Number of train examples = 566\n",
      "Number of dev examples = 30\n",
      "Total = 596\n",
      "-----\n",
      "\n",
      "Creating split 20\n",
      "Number of train examples = 587\n",
      "Number of dev examples = 31\n",
      "Total = 618\n",
      "-----\n",
      "\n",
      "Creating split 21\n",
      "Number of train examples = 607\n",
      "Number of dev examples = 32\n",
      "Total = 639\n",
      "-----\n",
      "\n",
      "Creating split 22\n",
      "Number of train examples = 627\n",
      "Number of dev examples = 34\n",
      "Total = 661\n",
      "-----\n",
      "\n",
      "Creating split 23\n",
      "Number of train examples = 648\n",
      "Number of dev examples = 35\n",
      "Total = 683\n",
      "-----\n",
      "\n",
      "Creating split 24\n",
      "Number of train examples = 669\n",
      "Number of dev examples = 36\n",
      "Total = 705\n",
      "-----\n",
      "\n",
      "Creating split 25\n",
      "Number of train examples = 690\n",
      "Number of dev examples = 37\n",
      "Total = 727\n",
      "-----\n",
      "\n",
      "Creating split 26\n",
      "Number of train examples = 711\n",
      "Number of dev examples = 38\n",
      "Total = 749\n",
      "-----\n",
      "\n",
      "Creating split 27\n",
      "Number of train examples = 732\n",
      "Number of dev examples = 39\n",
      "Total = 771\n",
      "-----\n",
      "\n",
      "Creating split 28\n",
      "Number of train examples = 753\n",
      "Number of dev examples = 40\n",
      "Total = 793\n",
      "-----\n",
      "\n",
      "Creating split 29\n",
      "Number of train examples = 774\n",
      "Number of dev examples = 41\n",
      "Total = 815\n",
      "-----\n",
      "\n",
      "Creating split 30\n",
      "Number of train examples = 795\n",
      "Number of dev examples = 42\n",
      "Total = 837\n",
      "-----\n",
      "\n",
      "Creating split 31\n",
      "Number of train examples = 816\n",
      "Number of dev examples = 43\n",
      "Total = 859\n",
      "-----\n",
      "\n",
      "Creating split 32\n",
      "Number of train examples = 828\n",
      "Number of dev examples = 44\n",
      "Total = 872\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create train-dev split\n",
    "for idx, split in enumerate(split_indices):\n",
    "    print(f'Creating split {idx+1}')\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        train_valid_sentences_concat[split], \n",
    "        train_valid_tags_concat[split], \n",
    "        test_size=0.05, \n",
    "        random_state=42)\n",
    "    \n",
    "    print(f'Number of train examples = {len(X_train)}')\n",
    "    print(f'Number of dev examples = {len(X_valid)}')\n",
    "    print(f'Total = {len(X_train)+len(X_valid)}')\n",
    "    \n",
    "    # Setup paths\n",
    "    split_dir_path = Path(f'{OUTPUT_DIR}/split{idx+1}')\n",
    "    split_dir_path.mkdir(exist_ok=True)\n",
    "\n",
    "    # Save training data\n",
    "    np.savetxt(f'{(split_dir_path/\"train.words.txt\")}', X_train, fmt='%s')\n",
    "    np.savetxt(f'{(split_dir_path/\"train.tags.txt\")}', np.array(list(map(lambda f: ' '.join(f), y_train))), fmt='%s')\n",
    "\n",
    "    # Save validation data\n",
    "    np.savetxt(f'{(split_dir_path/\"valid.words.txt\")}', X_valid, fmt='%s')\n",
    "    np.savetxt(f'{(split_dir_path/\"valid.tags.txt\")}', np.array(list(map(lambda f: ' '.join(f), y_valid))), fmt='%s')\n",
    "\n",
    "    # Save test set as-is\n",
    "    copy2(f'{DATA_DIR}/test.words.txt', f'{split_dir_path}/test.words.txt')\n",
    "    copy2(f'{DATA_DIR}/test.tags.txt', f'{split_dir_path}/test.tags.txt')\n",
    "\n",
    "    print('-'*5)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "14164fbe-8d5a-4659-9912-c0c98eb73ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stitch sentences and tags for model ingestion\n",
    "def stitch_files(words_file, tags_file, output_filepath='/tmp/concat_data.txt', sep='|||'):\n",
    "    '''\n",
    "    Given the words filepath (tokenized sentence per line) and\n",
    "    tags filepath (all tags of a sentence per line) and\n",
    "    a separator pattern (that is not already in the data),\n",
    "    create an `output_filepath` which concantenates the words\n",
    "    and tags into a single file.\n",
    "    '''\n",
    "    words = pd.read_csv(words_file, sep='|', header=None, names=['sentence'], quoting=3)\n",
    "    tags = pd.read_csv(tags_file, sep='|', header=None, names=['tags'], quoting=3)\n",
    "\n",
    "    assert words.shape[0] == tags.shape[0], 'Number of sentences and tags do not match'\n",
    "\n",
    "    concat_data = words['sentence'] + sep + tags['tags']\n",
    "    # print(concat_data)\n",
    "    concat_data.to_csv(output_filepath, sep='\\t', index=False, quoting=3, header=False)\n",
    "\n",
    "\n",
    "for data_split in ['train', 'valid', 'test']:\n",
    "    for split in range(1, 33):\n",
    "        words_file = f'/lfs1/shared/nlp/conll2003data/conll2003_partitions/federated_non_uniform_random/32-way/split{split}/{data_split}.words.txt'\n",
    "        tags_file = f'/lfs1/shared/nlp/conll2003data/conll2003_partitions/federated_non_uniform_random/32-way/split{split}/{data_split}.tags.txt'\n",
    "        output_file = f'/lfs1/shared/nlp/conll2003data/conll2003_partitions/federated_non_uniform_random/32-way/split{split}/{data_split}.words_tags.txt'\n",
    "\n",
    "        stitch_files(words_file, tags_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b369fb-54ad-49d7-99b7-d91ac111b520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
